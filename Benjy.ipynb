{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019feff",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.248Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tabula\n",
    "from tabula.io import read_pdf\n",
    "\n",
    "# read all pages of pdf document\n",
    "file_name = \"Hempstead.pdf\"\n",
    "dfs = tabula.io.read_pdf(file_name, pages='all', lattice=True)\n",
    "\n",
    "# concatenate all tables in pdf documents as one dataframe\n",
    "all_dfs=pd.concat(dfs)\n",
    "\n",
    "# take first 13 columns (some tables had a ghost 14th column)\n",
    "all_dfs=all_dfs.iloc[:,:13]\n",
    "\n",
    "# rename the dataframe's columns (names were long and poorly formatted)\n",
    "all_dfs.columns=[\"Property Info\",\n",
    "\"Name and Address\",\n",
    "\"Codes\",\n",
    "\"Full Market Value\",\n",
    "\"Land Assessed Value\",\n",
    "\"Total Assessed Value\",\n",
    "\"Exempt Code\",\n",
    "\"Exemption Amount\",\n",
    "\"Village Codes\",\n",
    "\"Rate Codes\",\n",
    "\"Tax District Percent\",\n",
    "\"Total Taxable Value Town\",\n",
    "\"Total Taxable Value County\"]\n",
    "\n",
    "# create one dataframe from the columns that do not need to be expanded (to be joined at the end)\n",
    "all_other_columns_df=all_dfs[[\"Full Market Value\",\n",
    "\"Land Assessed Value\",\n",
    "\"Total Assessed Value\",\n",
    "\"Exempt Code\",\n",
    "\"Exemption Amount\",\n",
    "\"Village Codes\",\n",
    "\"Rate Codes\",\n",
    "\"Tax District Percent\",\n",
    "\"Total Taxable Value Town\",\n",
    "\"Total Taxable Value County\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6716634",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.252Z"
    }
   },
   "outputs": [],
   "source": [
    "all_other_columns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6328385",
   "metadata": {},
   "source": [
    "## Splitting First column into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb80ae",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.292Z"
    }
   },
   "outputs": [],
   "source": [
    "# create multiple columns from the first column's rows (they are read and split on \"\\r\" character)\n",
    "series=all_dfs[\"Property Info\"].apply(lambda x:x.split(\"\\r\"))\n",
    "series_df=pd.DataFrame(data=series)\n",
    "series_df.columns=[\"First_Column\"]\n",
    "series_df[\"length\"]=series_df[\"First_Column\"].apply(lambda x:len(x))\n",
    "all_series=series_df[\"First_Column\"].tolist()\n",
    "\n",
    "# since many cells do not have a value for Lot Grouping, insert a blank value for that place in the list (so the columns aren't distorted)\n",
    "for series in all_series:\n",
    "    if 'acres' in series[2]:\n",
    "        series.insert(1,\"\")\n",
    "\n",
    "# take first 5 items from the list (which will create 5 columns in final dataframe). The bottom of the first cell has long code we don't need.\n",
    "all_series=[series[:5] for series in all_series]\n",
    "\n",
    "# create a dtaframe of 5 columns from the original first column\n",
    "first_column_df=pd.DataFrame(all_series, columns=['Section-Block-Lot', 'Lot Grouping', 'Address','Lot Size','Liber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af0b2c",
   "metadata": {},
   "source": [
    "## Splitting Second column into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7adc3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.304Z"
    }
   },
   "outputs": [],
   "source": [
    "# split on \"\\r\" character and handle issue with float that cannot be split (this came up in one of the 10,000 pages)\n",
    "address_series=all_dfs['Name and Address'].apply(lambda x:x.split(\"\\r\") if not(isinstance(x, float)) else [\"\",\"\",\"\",\"\"])\n",
    "address_series_df=pd.DataFrame(data=address_series)\n",
    "address_series_df.columns=[\"Second_Column\"]\n",
    "address_series_df[\"length\"]=address_series_df[\"Second_Column\"].apply(lambda x:len(x))\n",
    "all_address_series=address_series_df[\"Second_Column\"].tolist()\n",
    "\n",
    "# same concept as first column. In order to keep column names and values aligned, we add a blank value \n",
    "for series in all_address_series:\n",
    "    if len(series)==3:\n",
    "        series.insert(1,\"\")\n",
    "        series.insert(2,\"\")\n",
    "    elif len(series)==4:\n",
    "        if len(series[-1])<30:\n",
    "            series.insert(3,\"\")\n",
    "        else:\n",
    "            series.insert(1,\"\")\n",
    "            series.insert(2,\"\")\n",
    "    elif len(series)==5:\n",
    "        if len(series[-1])>20:\n",
    "            series.insert(2,\"\")\n",
    "    \n",
    "all_address_series=[series[:5] for series in all_address_series]\n",
    "\n",
    "# create a dtaframe of 4 columns from the original second column\n",
    "second_column_df=pd.DataFrame(all_address_series, columns=['Name 1', 'Name 2','Name 3','Street Address','City-State-Zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b7ce5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.306Z"
    }
   },
   "outputs": [],
   "source": [
    "# split on \"\\r\" character and handle issue with float that cannot be split (this came up in one of the 10,000 pages)\n",
    "address_series=all_dfs['Name and Address'].apply(lambda x:x.split(\"\\r\") if not(isinstance(x, float)) else [\"\",\"\",\"\",\"\"])\n",
    "address_series_df=pd.DataFrame(data=address_series)\n",
    "address_series_df.columns=[\"Second_Column\"]\n",
    "address_series_df[\"length\"]=address_series_df[\"Second_Column\"].apply(lambda x:len(x))\n",
    "all_address_series=address_series_df[\"Second_Column\"].tolist()\n",
    "\n",
    "# same concept as first column. In order to keep column names and values aligned, we add a blank value \n",
    "for series in all_address_series:\n",
    "    if len(series)==3:\n",
    "        series.insert(1,\"\")\n",
    "        series.insert(2,\"\")\n",
    "    elif len(series)==4:\n",
    "        if series[-1].count(\" \")<5:\n",
    "            series.insert(2,\"\")\n",
    "        else:\n",
    "            series.insert(1,\"\")\n",
    "            series.insert(2,\"\")\n",
    "    elif len(series)==5:\n",
    "        if series[-1].count(\" \")>4:\n",
    "            series.insert(2,\"\")\n",
    "    elif len(series)==6:\n",
    "        series.pop(1)\n",
    "    elif len(series)==7:\n",
    "        series.pop(1)\n",
    "        series.pop(3)\n",
    "    \n",
    "    \n",
    "all_address_series=[series[:5] for series in all_address_series]\n",
    "\n",
    "# create a dtaframe of 4 columns from the original second column\n",
    "second_column_df=pd.DataFrame(all_address_series, columns=['Name 1', 'Name 2','Name 3','Street Address','City-State-Zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e895ddc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.308Z"
    }
   },
   "outputs": [],
   "source": [
    "# split on \"\\r\" character \n",
    "codes_series=all_dfs['Codes'].apply(lambda x:x.split(\"\\r\"))\n",
    "codes_series_df=pd.DataFrame(data=codes_series)\n",
    "codes_series_df.columns=[\"Third_Column\"]\n",
    "all_codes_series=codes_series_df[\"Third_Column\"].tolist()\n",
    "\n",
    "# create a dtaframe of 6 columns from the original third column\n",
    "third_column_df=pd.DataFrame(all_codes_series, columns=['Roll Section', 'SWIS Code',\"Sch SWIS Code\",'School Code','PUC - Class',\"Percent Value\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20bb1b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.310Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge first, second, third dataframes with the rest of the columns\n",
    "final_df=pd.concat([first_column_df,second_column_df,third_column_df,all_other_columns_df.reset_index()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee0e28",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-25T17:03:44.311Z"
    }
   },
   "outputs": [],
   "source": [
    "#write final dataframe to csv\n",
    "final_df.to_csv(\"All_Properties.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461290d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
